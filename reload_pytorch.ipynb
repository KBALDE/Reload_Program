{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe0d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f28e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3512, 0.6443],\n",
      "         [0.0743, 0.1211]],\n",
      "\n",
      "        [[0.2680, 0.8293],\n",
      "         [0.7656, 0.8478]],\n",
      "\n",
      "        [[0.0930, 0.2398],\n",
      "         [0.3536, 0.6490]]])\n",
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,2, 2)\n",
    "print(x)\n",
    "\n",
    "print (torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746e207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensors\n",
    "ts = torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2bea8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.FloatTensor', torch.Size([3, 2, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(), ts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9bce8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3512, 0.6443],\n",
       "         [0.0743, 0.1211]],\n",
       "\n",
       "        [[0.2680, 0.8293],\n",
       "         [0.7656, 0.8478]],\n",
       "\n",
       "        [[0.0930, 0.2398],\n",
       "         [0.3536, 0.6490]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# channel first\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1d0b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to know which device\n",
    "ts.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abd72356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to put it on new device\n",
    "#ts.to(device) # device= device_name : gpu or else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bb51b631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shape # => it is channel first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd58ccee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensors like \n",
    "torch.zeros_like(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4fb9378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensors like \n",
    "torch.zeros_like(ts).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b71f6329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e3b378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1450, -0.3536],\n",
       "         [ 0.1732, -0.5340]],\n",
       "\n",
       "        [[-1.4056,  0.0913],\n",
       "         [-1.2498, -0.7992]],\n",
       "\n",
       "        [[-0.6458, -0.5966],\n",
       "         [ 0.3463, -0.1280]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15738789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3942, 0.9899],\n",
       "         [0.6222, 0.9364]],\n",
       "\n",
       "        [[0.5337, 0.5158],\n",
       "         [0.0728, 0.3121]],\n",
       "\n",
       "        [[0.7280, 0.9533],\n",
       "         [0.6479, 0.3007]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(ts) # the diff is that they are all positive number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "233f27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# program machine to learn implicitly by itself \n",
    "##=> artificial intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a908bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3bba654",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear=nn.Linear(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c82410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.linear.Linear"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d474ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=torch.randn(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da6d189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0744, -0.5053, -0.6831,  1.5158,  0.2813, -0.0693, -1.6677,  1.9224,\n",
       "         -0.3988,  0.4374],\n",
       "        [ 0.7357,  0.4680, -1.1798,  0.5303,  1.0260,  1.4791, -1.1641, -2.5352,\n",
       "         -2.2819, -0.8712],\n",
       "        [ 0.0910,  1.0212,  0.7148,  0.3808,  0.4776, -0.0509, -1.4244,  0.8427,\n",
       "         -0.0464,  1.5076]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92125d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick dense layer\n",
    "output=linear(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d9d6d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5811, -0.5773],\n",
       "        [ 0.1391,  0.3573],\n",
       "        [-0.6355, -1.1354]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8dceae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83d20f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pass it to the relu\n",
    "relu=nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff7f4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_output=relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b28cff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.1391, 0.3573],\n",
       "        [0.0000, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92ae152c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=2, bias=True)\n",
       "  (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimization\n",
    "import torch.optim as optim\n",
    "\n",
    "mlp_layer = nn.Sequential(nn.Linear(5, 2), nn.BatchNorm1d(2), nn.ReLU())\n",
    "mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8481854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.3022],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 1.0771],\n",
       "        [1.9866, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp=torch.randn(5, 5) + 1\n",
    "mlp_layer(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bea4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_opt= optim.Adam(mlp_layer.parameters(),lr=1e-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802afb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e88846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training exaples\n",
    "train_ex = torch.randn(100, 5) + 1\n",
    "\n",
    "# zero_ing out the grad\n",
    "adam_opt.zero_grad()\n",
    "\n",
    "# create the loss function\n",
    "curr_loss = torch.abs(1- mlp_layer(train_ex)).mean()\n",
    "\n",
    "# backward propagation\n",
    "curr_loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f6f4c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7858, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8603622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1a76953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7285, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over many step to perform the trianing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45217b3d",
   "metadata": {},
   "source": [
    "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
    "\n",
    "Tensors are similar to `NumPy’s ndarrays`, except that `tensors can run on GPUs or other hardware accelerators`. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data. \n",
    "\n",
    "Tensors are also optimized for automatic differentiation ( `Autograd` ). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a526dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = [[1, 2],[3, 4]]\n",
    "\n",
    "np_array = np.array(data)\n",
    "\n",
    "x_data = torch.from_numpy(np_array)\n",
    "\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a7f8e",
   "metadata": {},
   "source": [
    "From another tensor:\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "196bd894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9851, 0.0418],\n",
      "        [0.3785, 0.1223]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4bbcbf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d48a3ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6987, 0.6062, 0.9995],\n",
      "        [0.6105, 0.5326, 0.2657]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#With random or constant values:\n",
    "\n",
    "#shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of \n",
    "# the output tensor.\n",
    "\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451ce2e",
   "metadata": {},
   "source": [
    "#### Attributes of a Tensor\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "040876f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e7fe9",
   "metadata": {},
   "source": [
    "### Operations on Tensors\n",
    "Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a494621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3dcf687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# slicing like numpy\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ff895",
   "metadata": {},
   "source": [
    "**Joining tensors** You can use torch.cat to concatenate a sequence of tensors along a given dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6eecc89c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4f0f6",
   "metadata": {},
   "source": [
    "#### Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "04b90cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09dbaa8",
   "metadata": {},
   "source": [
    "**Single-element tensors** If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using item():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a706af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e09989",
   "metadata": {},
   "source": [
    "**In-place operations**: Operations that store the result into the operand are called in-place. They are denoted by a _ suffix. For example: x.copy_(y), x.t_(), will change x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "00935ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c91f2b",
   "metadata": {},
   "source": [
    "**In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770983b",
   "metadata": {},
   "source": [
    "### Bridge with NumPy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "44497c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# tensor to numpy\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\\n\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8b9efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# A change in the tensor reflects in the NumPy array.\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87015963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Numpy array to Tensor\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "print(f\"{n}\\n\")\n",
    "print(f\"{t}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f00bec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "#Changes in the NumPy array reflects in the tensor.\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ed1fb",
   "metadata": {},
   "source": [
    "## QUICKSTART\n",
    "\n",
    "### Working with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038152e",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch has two primitives to work with data: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset`.\n",
    "\n",
    "- **Dataset** stores the samples and their corresponding labels, \n",
    "- and **DataLoader** wraps an iterable around the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9d30330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ddb9d",
   "metadata": {},
   "source": [
    "PyTorch offers domain-specific libraries such as `TorchText, TorchVision, and TorchAudio`, all of which include datasets. For this tutorial, we will be using a **TorchVision** dataset.\n",
    "\n",
    "\n",
    "Every `TorchVision` Dataset includes two arguments: `transform` and `target_transform` to modify the samples and labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3f9dce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf941ed",
   "metadata": {},
   "source": [
    "We pass the `Dataset` as an argument to `DataLoader`. This wraps an iterable over our dataset, and supports automatic `batching, sampling, shuffling and multiprocess` data loading. \n",
    "\n",
    "Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f43b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b617fa",
   "metadata": {},
   "source": [
    "### Creating Models\n",
    "\n",
    "To define a neural network in PyTorch, we create a class that inherits from `nn.Module`. We define the layers of the network in the `__init__` function and specify how data will pass through the network in the `forward function`. To accelerate operations in the neural network, we move it to the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d207122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e593503",
   "metadata": {},
   "source": [
    "### Optimizing the Model Parameters\n",
    "To train a model, we need a `loss function and an optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "467a36b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cd9bd",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48cddfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # model is fitted here\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a15603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a315310",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (epochs). During each epoch, the model learns parameters to make better predictions. We print the model’s accuracy and loss at each epoch; we’d like to see the accuracy increase and the loss decrease with every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39fb5cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.308942  [    0/60000]\n",
      "loss: 2.289799  [ 6400/60000]\n",
      "loss: 2.270063  [12800/60000]\n",
      "loss: 2.258061  [19200/60000]\n",
      "loss: 2.247024  [25600/60000]\n",
      "loss: 2.209643  [32000/60000]\n",
      "loss: 2.217358  [38400/60000]\n",
      "loss: 2.185217  [44800/60000]\n",
      "loss: 2.189134  [51200/60000]\n",
      "loss: 2.147979  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 2.140819 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.159720  [    0/60000]\n",
      "loss: 2.141727  [ 6400/60000]\n",
      "loss: 2.081944  [12800/60000]\n",
      "loss: 2.094977  [19200/60000]\n",
      "loss: 2.044767  [25600/60000]\n",
      "loss: 1.981107  [32000/60000]\n",
      "loss: 2.006166  [38400/60000]\n",
      "loss: 1.928531  [44800/60000]\n",
      "loss: 1.942596  [51200/60000]\n",
      "loss: 1.857719  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.854838 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.898327  [    0/60000]\n",
      "loss: 1.859793  [ 6400/60000]\n",
      "loss: 1.737964  [12800/60000]\n",
      "loss: 1.776949  [19200/60000]\n",
      "loss: 1.667548  [25600/60000]\n",
      "loss: 1.623609  [32000/60000]\n",
      "loss: 1.639525  [38400/60000]\n",
      "loss: 1.545207  [44800/60000]\n",
      "loss: 1.578647  [51200/60000]\n",
      "loss: 1.466176  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.486929 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.558767  [    0/60000]\n",
      "loss: 1.523223  [ 6400/60000]\n",
      "loss: 1.371097  [12800/60000]\n",
      "loss: 1.441912  [19200/60000]\n",
      "loss: 1.324495  [25600/60000]\n",
      "loss: 1.326171  [32000/60000]\n",
      "loss: 1.332332  [38400/60000]\n",
      "loss: 1.263648  [44800/60000]\n",
      "loss: 1.303309  [51200/60000]\n",
      "loss: 1.200978  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.231470 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.309698  [    0/60000]\n",
      "loss: 1.293690  [ 6400/60000]\n",
      "loss: 1.127598  [12800/60000]\n",
      "loss: 1.230019  [19200/60000]\n",
      "loss: 1.105969  [25600/60000]\n",
      "loss: 1.135801  [32000/60000]\n",
      "loss: 1.148520  [38400/60000]\n",
      "loss: 1.091848  [44800/60000]\n",
      "loss: 1.135064  [51200/60000]\n",
      "loss: 1.049337  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.074059 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24293ae8",
   "metadata": {},
   "source": [
    "### Saving Models\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b155e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c45b7",
   "metadata": {},
   "source": [
    "### Loading Models\n",
    "The process for loading a model includes re-creating the model structure and loading the state dictionary into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7756387a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "266051b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# now, let's make prediction\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "622d9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref : https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
